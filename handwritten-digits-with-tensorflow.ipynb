{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digits with Tensorflow\n",
    "In this notebook I'll build a Neural Network that recognize handwritten digits, using Tensorflow.\n",
    "Each image is a `28x28` pixels, and for each one is associated a label with the corresponding digit from `0` to `9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using in this tutorial is called the `MNIST` dataset, and it is a classic in the machine learning community. This dataset is made up of images of handwritten digits, 28x28 pixels in size. Here are some examples of the digits included in the dataset:  <img src=\"digits.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)  # y labels are hot-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = mnist.train.num_examples  # 55,000\n",
    "n_validation = mnist.validation.num_examples  # 5000\n",
    "n_test = mnist.test.num_examples  # 10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784  # input layer (28x28 pixels)\n",
    "n_hidden1 = 512  # 1st hidden layer\n",
    "n_hidden2 = 256  # 2nd hidden layer\n",
    "n_hidden3 = 128  # 3rd hidden layer\n",
    "n_output = 10  # output layer (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following diagram shows a visualization of the architecture we’ve designed, with each layer fully connected to the surrounding layers:  <img src=\"neural_network.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network hyperparameters\n",
    "n_iterations = 10000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining tensors\n",
    "inputs = tf.placeholder(tf.float32, shape=(None, n_input), name='inputs')\n",
    "labels = tf.placeholder(tf.float32, shape=(None, n_output), name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-103b8f1c0403>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\pc\\miniconda3\\envs\\tflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# defining Layers\n",
    "hidden1 = tf.layers.dense(inputs, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name='hidden1')\n",
    "hidden2 = tf.layers.dense(inputs, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name='hidden2')\n",
    "hidden3 = tf.layers.dense(inputs, n_hidden3,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name='hidden3')\n",
    "logits = tf.layers.dense(hidden2, n_output,\n",
    "                             name='logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function\n",
    "\n",
    "# convert labels to tf.float32\n",
    "labels_float = tf.cast(labels, tf.float32)\n",
    "\n",
    "# calculate the cross entropy using softmax\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels_float, logits=logits)    \n",
    "\n",
    "# calculate the loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# set the training operation using AdamOptimizer\n",
    "adam = tf.train.AdamOptimizer()\n",
    "train_op = adam.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve now defined the network and built it out with TensorFlow. The next step is to feed data through the graph to train it, and then test that it has actually learned something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the training process, we will define our method of evaluating the accuracy so we can print it out on mini-batches of data while we train. These printed statements will allow us to check that from the first iteration to the last, loss decreases and accuracy increases; they will also allow us to track whether or not we have ran enough iterations to reach a consistent and optimal result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the accuracy\n",
    "\n",
    "# calculate the probabilities from logits using the softmax function\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "# calculate label predictions using argmax\n",
    "predictions = tf.argmax(probs, axis=-1)\n",
    "\n",
    "# convert labels back to class indexes to calculate our accuracy (from hot vectors)\n",
    "class_labels = tf.argmax(labels, axis=-1)\n",
    "\n",
    "# calculate the number of false and true predictions\n",
    "is_correct = tf.equal(predictions, class_labels)\n",
    "\n",
    "# calculate the accuracy of our model\n",
    "is_correct_float = tf.cast(is_correct, tf.float32)\n",
    "accuracy = tf.reduce_mean(is_correct_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to initialize a session for running the graph. In this session we will feed the network with our training examples, and once trained, we feed the same graph with new test examples to determine the accuracy of the model. Add the following lines of code to your file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 2.0769043 \t| Accuracy = 0.34375\n",
      "Iteration 1000 \t| Loss = 0.1598415 \t| Accuracy = 0.953125\n",
      "Iteration 2000 \t| Loss = 0.047629982 \t| Accuracy = 0.984375\n",
      "Iteration 3000 \t| Loss = 0.21690081 \t| Accuracy = 0.953125\n",
      "Iteration 4000 \t| Loss = 0.016726766 \t| Accuracy = 1.0\n",
      "Iteration 5000 \t| Loss = 0.0046698255 \t| Accuracy = 1.0\n",
      "Iteration 6000 \t| Loss = 0.005712395 \t| Accuracy = 1.0\n",
      "Iteration 7000 \t| Loss = 0.0010352945 \t| Accuracy = 1.0\n",
      "Iteration 8000 \t| Loss = 0.011212721 \t| Accuracy = 1.0\n",
      "Iteration 9000 \t| Loss = 0.008898743 \t| Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# startegy 2 for training\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "    \n",
    "for i in range(n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    feed_dict = {\n",
    "        inputs: batch_x,\n",
    "        labels: batch_y\n",
    "    }\n",
    "    sess.run(train_op, feed_dict=feed_dict)\n",
    "    \n",
    "    # print loss and accuracy (per minibatch)\n",
    "    if i % 1000 == 0:\n",
    "        minibatch_loss, minibatch_accuracy = sess.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={inputs: batch_x, labels: batch_y}\n",
    "        )\n",
    "        print(\n",
    "            \"Iteration\",\n",
    "            str(i),\n",
    "            \"\\t| Loss =\",\n",
    "            str(minibatch_loss),\n",
    "            \"\\t| Accuracy =\",\n",
    "            str(minibatch_accuracy)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is complete, we can run the session on the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on test set: 0.9795\n"
     ]
    }
   ],
   "source": [
    "# strategy 2 for testing\n",
    "test_accuracy = sess.run(accuracy, feed_dict={inputs: mnist.test.images,\\\n",
    "                                              labels: mnist.test.labels})\n",
    "print(\"\\nAccuracy on test set:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate that the network is actually recognizing the hand-drawn images, let’s test it on a single image of our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA1UlEQVR4nO3VMQ5EERAG4LWVUqnkVkqlWygdQcktuJnSdi/zLPNGotlkp3zhi3/iDdZ7f52u93Hxp9Faq9aazUprnXMmqR1UKUUIga9XSqWUOlo3VEpJDIjTN/Ta45wb1oUQBpdzvoeuVg/0Hoqkgy0ioZxzPF2MEWnRHIXpvvfAu2GMWYkjihcM3lo7gBKDb6D04FR0+M3w4FQUtvIxOAndaiUVvY5JaeUzmlJSSm218gGFqXePuUQpMxCZD3MUDgGkVtNv/kZ57ymotXb6nfX/u3+6PrrHXUteRjRGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x1A3818DE898>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picture = Image.open(\"test_image.png\")\n",
    "picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.invert(picture.convert('L')).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `open` function of the `Image` library loads the test image as a 4D array containing the three RGB color channels and the Alpha transparency. This is not the same representation we used previously when reading in the dataset with TensorFlow, so we’ll need to do some extra work to match the format.\n",
    "\n",
    "First, we use the `convert` function with the `L` parameter to reduce the 4D RGBA representation to one grayscale color channel. We store this as a `numpy` array and invert it using `np.invert`, because the current matrix represents black as 0 and white as 255, whereas we need the opposite. Finally, we call `ravel` to flatten the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the image data is structured correctly, we can run a session in the same way as previously, but this time only feeding in the single image for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test image: 2\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run(tf.argmax(logits, 1), feed_dict={inputs: [img]})\n",
    "print (\"Prediction for test image:\", np.squeeze(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAAM! WORKS LIKE A CHARM!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
